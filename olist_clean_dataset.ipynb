{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95eefaca",
   "metadata": {},
   "source": [
    "# Olist E-commerce Dataset Cleaning\n",
    "**Project Goal:** Prepare and standardize the Olist dataset to ensure high-quality, reliable data for SQL analysis and business insights extraction.\n",
    "\n",
    "## Dataset Overview\n",
    "The Brazilian E-Commerce Public Dataset by Olist contains detailed records of orders made at a multi-vendor marketplace in Brazil from 2016 to 2018. It includes data across:\n",
    "\n",
    "- Orders\n",
    "- Customers\n",
    "- Sellers\n",
    "- Order items\n",
    "- Products\n",
    "- Payments\n",
    "- Reviews\n",
    "- Geolocation\n",
    "- Product category translations\n",
    "\n",
    "## Data Analysis Workflow\n",
    "\n",
    "1. **Data Retrieval** – Load and inspect the datasets provided.\n",
    "2. **Initial Exploration** – Understand the structure, shape, and basic contents of the data.\n",
    "3. **Data Cleaning** – Handle missing values, data types, duplicates, and inconsistencies.\n",
    "\n",
    "---\n",
    "\n",
    "## Load the Dataset\n",
    "**Action:** Import all relevant CSV files into pandas DataFrames.  \n",
    "**Purpose:** Gain an initial understanding of the raw dataset and establish a foundation for exploratory analysis and cleaning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76cf58f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#File path\n",
    "customers_fp=\"/Users/neha/Documents/Sql Projects/Olist_Ecommerce_SQL_Project/Dataset Cleaning with Pandas/olist_customers_dataset.csv\"\n",
    "geoloc_fp=\"/Users/neha/Documents/Sql Projects/Olist_Ecommerce_SQL_Project/Dataset Cleaning with Pandas/olist_geolocation_dataset.csv\"\n",
    "order_items_fp=\"/Users/neha/Documents/Sql Projects/Olist_Ecommerce_SQL_Project/Dataset Cleaning with Pandas/olist_order_items_dataset.csv\"\n",
    "order_payments_fp=\"/Users/neha/Documents/Sql Projects/Olist_Ecommerce_SQL_Project/Dataset Cleaning with Pandas/olist_order_payments_dataset.csv\"\n",
    "order_reviews_fp=\"/Users/neha/Documents/Sql Projects/Olist_Ecommerce_SQL_Project/Dataset Cleaning with Pandas/olist_order_reviews_dataset.csv\"\n",
    "orders_fp=\"/Users/neha/Documents/Sql Projects/Olist_Ecommerce_SQL_Project/Dataset Cleaning with Pandas/olist_orders_dataset.csv\"\n",
    "products_fp=\"/Users/neha/Documents/Sql Projects/Olist_Ecommerce_SQL_Project/Dataset Cleaning with Pandas/olist_products_dataset.csv\"\n",
    "sellers_fp=\"/Users/neha/Documents/Sql Projects/Olist_Ecommerce_SQL_Project/Dataset Cleaning with Pandas/olist_sellers_dataset.csv\"\n",
    "category_name_translation_fp=\"/Users/neha/Documents/Sql Projects/Olist_Ecommerce_SQL_Project/Dataset Cleaning with Pandas/product_category_name_translation.csv\"\n",
    "\n",
    "#Loading the datasets\n",
    "customers=pd.read_csv(customers_fp)\n",
    "geoloc=pd.read_csv(geoloc_fp)\n",
    "order_items=pd.read_csv(order_items_fp)\n",
    "order_payments=pd.read_csv(order_payments_fp)\n",
    "order_reviews=pd.read_csv(order_reviews_fp)\n",
    "orders=pd.read_csv(orders_fp)\n",
    "products=pd.read_csv(products_fp)\n",
    "sellers=pd.read_csv(sellers_fp)\n",
    "category_name_translation=pd.read_csv(category_name_translation_fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f526877",
   "metadata": {},
   "source": [
    "### Initial Exploration\n",
    "- Check dataset shape, column names, and data types.\n",
    "- Identify missing values and duplicates.\n",
    "- Document any immediate issues for cleaning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2f07e3",
   "metadata": {},
   "source": [
    "### 1. Customers Dataset\n",
    "This dataset contains information about unique customers, including:\n",
    "- **customer_id** (unique identifier for each customer)\n",
    "- **customer_unique_id** (unique across time, even if the same customer places multiple orders)\n",
    "- **customer_zip_code_prefix**, **customer_city**, **customer_state**\n",
    "\n",
    "### Exploration Steps:\n",
    "- Check dataset shape\n",
    "- Review column data types\n",
    "- Identify missing values\n",
    "- Preview sample rows\n",
    "- Summarize numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f5493d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99441, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06b8999e2fba1a1fbc88172c00ba8bc7</td>\n",
       "      <td>861eff4711a542e4b93843c6dd7febb0</td>\n",
       "      <td>14409</td>\n",
       "      <td>franca</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18955e83d337fd6b2def6b18a428ac77</td>\n",
       "      <td>290c77bc529b7ac935b93aa66c333dc3</td>\n",
       "      <td>9790</td>\n",
       "      <td>sao bernardo do campo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e7b3e00288586ebd08712fdd0374a03</td>\n",
       "      <td>060e732b5b29e8181a18229c7b0b2b5e</td>\n",
       "      <td>1151</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2b6027bc5c5109e529d4dc6358b12c3</td>\n",
       "      <td>259dac757896d24d7702b9acbbff3f3c</td>\n",
       "      <td>8775</td>\n",
       "      <td>mogi das cruzes</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4f2d8ab171c80ec8364f7c12e35b23ad</td>\n",
       "      <td>345ecd01c38d18a9036ed96c73b8d066</td>\n",
       "      <td>13056</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        customer_id                customer_unique_id  \\\n",
       "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
       "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
       "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
       "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
       "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
       "\n",
       "   customer_zip_code_prefix          customer_city customer_state  \n",
       "0                     14409                 franca             SP  \n",
       "1                      9790  sao bernardo do campo             SP  \n",
       "2                      1151              sao paulo             SP  \n",
       "3                      8775        mogi das cruzes             SP  \n",
       "4                     13056               campinas             SP  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(customers.shape)\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc06e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   customer_id               99441 non-null  object\n",
      " 1   customer_unique_id        99441 non-null  object\n",
      " 2   customer_zip_code_prefix  99441 non-null  int64 \n",
      " 3   customer_city             99441 non-null  object\n",
      " 4   customer_state            99441 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "customer_id                 0\n",
       "customer_unique_id          0\n",
       "customer_zip_code_prefix    0\n",
       "customer_city               0\n",
       "customer_state              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers.info()\n",
    "customers.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f87166",
   "metadata": {},
   "source": [
    "### Customers Dataset – Findings  \n",
    "\n",
    "- **Missing Values**: None found.  \n",
    "- **Duplicate Rows**: None found.  \n",
    "- **Data Types**: All columns have appropriate datatypes.  \n",
    "- **Data Integrity**:  \n",
    "  - Each `customer_id` is unique.  \n",
    "  - `customer_unique_id` can appear multiple times since one customer may place multiple orders.  \n",
    "\n",
    "No major cleaning required for this dataset. It is ready to be used for further analysis and joins with other tables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f565d86",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Orders Dataset  \n",
    "Contains order lifecycle details with timestamps and status info.  \n",
    "Key fields: `order_id`, `customer_id`, `order_status`, `purchase_timestamp`, `delivered_customer_date`, `estimated_delivery_date`.  \n",
    "\n",
    "We'll explore its structure and note any potential data quality issues. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15f38405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99441, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-18 19:45:59</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-13 22:20:29</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
       "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
       "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
       "\n",
       "  order_estimated_delivery_date  \n",
       "0           2017-10-18 00:00:00  \n",
       "1           2018-08-13 00:00:00  \n",
       "2           2018-09-04 00:00:00  \n",
       "3           2017-12-15 00:00:00  \n",
       "4           2018-02-26 00:00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   order_id                       99441 non-null  object\n",
      " 1   customer_id                    99441 non-null  object\n",
      " 2   order_status                   99441 non-null  object\n",
      " 3   order_purchase_timestamp       99441 non-null  object\n",
      " 4   order_approved_at              99281 non-null  object\n",
      " 5   order_delivered_carrier_date   97658 non-null  object\n",
      " 6   order_delivered_customer_date  96476 non-null  object\n",
      " 7   order_estimated_delivery_date  99441 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 6.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "order_status\n",
       "delivered      96478\n",
       "shipped         1107\n",
       "canceled         625\n",
       "unavailable      609\n",
       "invoiced         314\n",
       "processing       301\n",
       "created            5\n",
       "approved           2\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(orders.shape)\n",
    "display(orders.head())\n",
    "display(orders.info())\n",
    "display(orders['order_status'].value_counts())\n",
    "orders.isnull().sum()\n",
    "display(orders.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551f6df9",
   "metadata": {},
   "source": [
    "### Orders Dataset- Findings\n",
    "- 8 `order_status` values: delivered, shipped, canceled, processing, invoiced, unavailable, etc.\n",
    "- `order_id` is the primary key links to `order_items`, `order_payments`, `order_reviews`, and `customers`.\n",
    "- Timestamps are objects which needs conversion to `datetime` for analysis.\n",
    "- Missing values are meaningful (e.g., canceled orders may lack approval or delivery dates).\n",
    "- `order_estimated_delivery_date` has only the date, no time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995bff95",
   "metadata": {},
   "source": [
    "### Orders Dataset - Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3772a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the datatype of timestamp columns to datetime\n",
    "date_cols = [\n",
    "    'order_purchase_timestamp', \n",
    "    'order_approved_at', \n",
    "    'order_delivered_carrier_date', \n",
    "    'order_delivered_customer_date', \n",
    "    'order_estimated_delivery_date'\n",
    "]\n",
    "for col in date_cols:\n",
    "    orders[col] = pd.to_datetime(orders[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "240bd1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 1382 entries, 15 to 99406\n",
      "Series name: order_delivered_carrier_date\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "1382 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 21.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#Removing all the absurd orders that do not make sense\n",
    "#example: delivered date before purchase date\n",
    "invalid_orders = orders[\n",
    "    (orders['order_approved_at'] < orders['order_purchase_timestamp']) |\n",
    "    (orders['order_delivered_carrier_date'] < orders['order_approved_at']) |\n",
    "    (orders['order_delivered_customer_date'] < orders['order_delivered_carrier_date']) |\n",
    "    (orders['order_estimated_delivery_date'] < orders['order_purchase_timestamp'])\n",
    "]\n",
    "invalid_orders['order_delivered_carrier_date'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa4ad0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1373 entries, 15 to 99406\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   order_id                       1373 non-null   object\n",
      " 1   customer_id                    1373 non-null   object\n",
      " 2   order_status                   1373 non-null   object\n",
      " 3   order_purchase_timestamp       1373 non-null   object\n",
      " 4   order_approved_at              1373 non-null   object\n",
      " 5   order_delivered_carrier_date   1373 non-null   object\n",
      " 6   order_delivered_customer_date  1373 non-null   object\n",
      " 7   order_estimated_delivery_date  1373 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 96.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 98068 entries, 0 to 98067\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   order_id                       98068 non-null  object\n",
      " 1   customer_id                    98068 non-null  object\n",
      " 2   order_status                   98068 non-null  object\n",
      " 3   order_purchase_timestamp       98068 non-null  object\n",
      " 4   order_approved_at              97908 non-null  object\n",
      " 5   order_delivered_carrier_date   96285 non-null  object\n",
      " 6   order_delivered_customer_date  95103 non-null  object\n",
      " 7   order_estimated_delivery_date  98068 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#Carefully examining the invalid orders to remove only the truly invalid ones\n",
    "null_invalid_orders = invalid_orders[invalid_orders['order_delivered_customer_date'].isnull()] \n",
    "invalid_orders = invalid_orders.drop(null_invalid_orders.index) \n",
    "invalid_orders.info() \n",
    "# Remove invalid orders from the main orders DataFrame using 'order_id' and reset index\n",
    "orders_cleaned = orders[~orders['order_id'].isin(invalid_orders['order_id'])].reset_index(drop=True)\n",
    "orders_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1915b372",
   "metadata": {},
   "source": [
    "### 3. Orders Items Dataset\n",
    "This dataset contains details about each item in an order, including product info, seller, price, freight, and sequence within the order.\n",
    "\n",
    "Columns:\n",
    "- order_id → links to orders\n",
    "- order_item_id → item sequence in the order\n",
    "- product_id → links to products\n",
    "- seller_id → links to sellers\n",
    "- shipping_limit_date → expected shipment date\n",
    "- price → item price\n",
    "- freight_value → shipping cost\n",
    "\n",
    "We will explore to find any issues with structure or to improve quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5d5abe12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112650, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_item_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>last_shipping_date</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00010242fe8c5a6d1ba2dd792cb16214</td>\n",
       "      <td>1</td>\n",
       "      <td>4244733e06e7ecb4970a6e2683c13e61</td>\n",
       "      <td>48436dade18ac8b2bce089ec2a041202</td>\n",
       "      <td>2017-09-19 09:45:35</td>\n",
       "      <td>58.90</td>\n",
       "      <td>13.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00018f77f2f0320c557190d7a144bdd3</td>\n",
       "      <td>1</td>\n",
       "      <td>e5f2d52b802189ee658865ca93d83a8f</td>\n",
       "      <td>dd7ddc04e1b6c2c614352b383efe2d36</td>\n",
       "      <td>2017-05-03 11:05:13</td>\n",
       "      <td>239.90</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000229ec398224ef6ca0657da4fc703e</td>\n",
       "      <td>1</td>\n",
       "      <td>c777355d18b72b67abbeef9df44fd0fd</td>\n",
       "      <td>5b51032eddd242adc84c38acab88f23d</td>\n",
       "      <td>2018-01-18 14:48:30</td>\n",
       "      <td>199.00</td>\n",
       "      <td>17.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00024acbcdf0a6daa1e931b038114c75</td>\n",
       "      <td>1</td>\n",
       "      <td>7634da152a4610f1595efa32f14722fc</td>\n",
       "      <td>9d7a1d34a5052409006425275ba1c2b4</td>\n",
       "      <td>2018-08-15 10:10:18</td>\n",
       "      <td>12.99</td>\n",
       "      <td>12.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00042b26cf59d7ce69dfabb4e55b4fd9</td>\n",
       "      <td>1</td>\n",
       "      <td>ac6c3623068f30de03045865e4e10089</td>\n",
       "      <td>df560393f3a51e74553ab94004ba5c87</td>\n",
       "      <td>2017-02-13 13:57:51</td>\n",
       "      <td>199.90</td>\n",
       "      <td>18.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id  order_item_id  \\\n",
       "0  00010242fe8c5a6d1ba2dd792cb16214              1   \n",
       "1  00018f77f2f0320c557190d7a144bdd3              1   \n",
       "2  000229ec398224ef6ca0657da4fc703e              1   \n",
       "3  00024acbcdf0a6daa1e931b038114c75              1   \n",
       "4  00042b26cf59d7ce69dfabb4e55b4fd9              1   \n",
       "\n",
       "                         product_id                         seller_id  \\\n",
       "0  4244733e06e7ecb4970a6e2683c13e61  48436dade18ac8b2bce089ec2a041202   \n",
       "1  e5f2d52b802189ee658865ca93d83a8f  dd7ddc04e1b6c2c614352b383efe2d36   \n",
       "2  c777355d18b72b67abbeef9df44fd0fd  5b51032eddd242adc84c38acab88f23d   \n",
       "3  7634da152a4610f1595efa32f14722fc  9d7a1d34a5052409006425275ba1c2b4   \n",
       "4  ac6c3623068f30de03045865e4e10089  df560393f3a51e74553ab94004ba5c87   \n",
       "\n",
       "   last_shipping_date   price  freight_value  \n",
       "0 2017-09-19 09:45:35   58.90          13.29  \n",
       "1 2017-05-03 11:05:13  239.90          19.93  \n",
       "2 2018-01-18 14:48:30  199.00          17.87  \n",
       "3 2018-08-15 10:10:18   12.99          12.79  \n",
       "4 2017-02-13 13:57:51  199.90          18.14  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   order_id            112650 non-null  object        \n",
      " 1   order_item_id       112650 non-null  int64         \n",
      " 2   product_id          112650 non-null  object        \n",
      " 3   seller_id           112650 non-null  object        \n",
      " 4   last_shipping_date  112650 non-null  datetime64[ns]\n",
      " 5   price               112650 non-null  float64       \n",
      " 6   freight_value       112650 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(3)\n",
      "memory usage: 6.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "order_id              98666\n",
       "order_item_id            21\n",
       "product_id            32951\n",
       "seller_id              3095\n",
       "last_shipping_date    93318\n",
       "price                  5968\n",
       "freight_value          6999\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploring order_items dataset\n",
    "display(order_items.shape)\n",
    "display(order_items.head())\n",
    "display(order_items.info())\n",
    "order_items.isnull().sum()\n",
    "order_items.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0047c743",
   "metadata": {},
   "source": [
    "### Order Items Dataset - Findings\n",
    "- There are no missing values in key columns (`order_id`, `product_id`, `seller_id`)\n",
    "- `shipping_limit_date` needs conversion from objects to datetime type for easier calculations of delivery performance.\n",
    "- `price` and `freight_value` are crucial for revenue analysis, so we'll ensure they are non-negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2e72ae",
   "metadata": {},
   "source": [
    "### Order Items - Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97425a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the datatype of shipping_limit_date to datetime\n",
    "order_items['shipping_limit_date'] = pd.to_datetime(order_items['shipping_limit_date'], errors='coerce')\n",
    "#Renaming shipping_limit_date to last_shipping_date for consistency\n",
    "order_items = order_items.rename(columns={'shipping_limit_date': 'last_shipping_date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4564b3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   order_id             112650 non-null  object \n",
      " 1   order_item_id        112650 non-null  int64  \n",
      " 2   product_id           112650 non-null  object \n",
      " 3   seller_id            112650 non-null  object \n",
      " 4   shipping_limit_date  112650 non-null  object \n",
      " 5   price                112650 non-null  float64\n",
      " 6   freight_value        112650 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "order_items.shape\n",
    "#Checking for negative prices and freight values\n",
    "invalid_prices = order_items[order_items['price'] < 0]\n",
    "invalid_freight = order_items[order_items['freight_value'] < 0]\n",
    "order_items.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e945b92",
   "metadata": {},
   "source": [
    "### 4. Order Payments\n",
    "This dataset contains information about payments for each order, including payment type, amount, and number of installments.\n",
    "\n",
    "Column:\n",
    "- order_id → links to the orders table\n",
    "- payment_sequential → sequence of payments for the same order\n",
    "- payment_type → method of payment (credit card, boleto, etc.)\n",
    "- payment_installments → number of installments\n",
    "- payment_value → amount paid\n",
    "\n",
    "We will explore to find any issues with structure or to improve quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1f56dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103875, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>payment_sequential</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>payment_installments</th>\n",
       "      <th>payment_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b81ef226f3fe1789b1e8b2acac839d17</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>8</td>\n",
       "      <td>99.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a9810da82917af2d9aefd1278f1dcfa0</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>1</td>\n",
       "      <td>24.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25e8ea4e93396b6fa0d3dd708e76c1bd</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>1</td>\n",
       "      <td>65.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ba78997921bbcdc1373bb41e913ab953</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>8</td>\n",
       "      <td>107.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42fdf880ba16b47b59251dd489d4441a</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>2</td>\n",
       "      <td>128.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id  payment_sequential payment_type  \\\n",
       "0  b81ef226f3fe1789b1e8b2acac839d17                   1  credit_card   \n",
       "1  a9810da82917af2d9aefd1278f1dcfa0                   1  credit_card   \n",
       "2  25e8ea4e93396b6fa0d3dd708e76c1bd                   1  credit_card   \n",
       "3  ba78997921bbcdc1373bb41e913ab953                   1  credit_card   \n",
       "4  42fdf880ba16b47b59251dd489d4441a                   1  credit_card   \n",
       "\n",
       "   payment_installments  payment_value  \n",
       "0                     8          99.33  \n",
       "1                     1          24.39  \n",
       "2                     1          65.71  \n",
       "3                     8         107.78  \n",
       "4                     2         128.45  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103875 entries, 0 to 103874\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   order_id              103875 non-null  object \n",
      " 1   payment_sequential    103875 non-null  int64  \n",
      " 2   payment_type          103875 non-null  object \n",
      " 3   payment_installments  103875 non-null  int64  \n",
      " 4   payment_value         103875 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 4.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "payment_type\n",
       "credit_card    76793\n",
       "boleto         19784\n",
       "voucher         5769\n",
       "debit_card      1529\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display (order_payments.shape)\n",
    "display (order_payments.head())\n",
    "display (order_payments.info())\n",
    "order_payments.isnull().sum()\n",
    "order_payments.nunique()\n",
    "order_payments.duplicated().sum()\n",
    "order_payments['payment_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db9d38a",
   "metadata": {},
   "source": [
    "### Order Payment - Findings\n",
    "- No missing values found in key coulumn (`order_id`)\n",
    "- Orders may repeat if the payment is done in installments.\n",
    "- `payment_value` should not be negative.\n",
    "- `payment_installments` should be positive (>=1)\n",
    "- This dataset is crucial in analyzing payment behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abde224",
   "metadata": {},
   "source": [
    "### Order Payment - Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ea46f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid payment_value rows: 0\n",
      "Invalid payment_installments rows: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "payment_type\n",
       "credit_card    76793\n",
       "boleto         19784\n",
       "voucher         5769\n",
       "debit_card      1529\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for negative payment values and drop those rows\n",
    "invalid_payments = order_payments[order_payments['payment_value'] <= 0]\n",
    "order_payments = order_payments[order_payments['payment_value'] > 0].reset_index(drop=True)\n",
    "print(f\"Invalid payment_value rows: {invalid_payments.shape[0]}\")\n",
    "\n",
    "#Checking for invalid payment installments (should be >=1)\n",
    "invalid_installments = order_payments[order_payments['payment_installments'] < 1]\n",
    "order_payments =order_payments[order_payments['payment_installments'] >= 1].reset_index(drop=True)\n",
    "print(f\"Invalid payment_installments rows: {invalid_installments.shape[0]}\")\n",
    "\n",
    "order_payments['payment_type'].value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83b5fa47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103875, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_payments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77416710",
   "metadata": {},
   "source": [
    "### 5. Order Reviews\n",
    "This dateset contains customer feedback for completed orders.\n",
    "\n",
    "- review_id → Unique identifier for each review.\n",
    "- order_id → Links the review to the corresponding order in the orders dataset.\n",
    "- review_score → Rating from 1 to 5 (1 = very bad, 5 = very good).\n",
    "- review_comment_title → Optional short summary of the review (text).\n",
    "- review_comment_message → Optional detailed review (text).\n",
    "- review_creation_date → When the review was created (string, needs datetime conversion).\n",
    "- review_answer_timestamp → When Olist responded/registered the review (string, needs datetime conversion).\n",
    "\n",
    "We will explore this dataset to find any issues with structure and to improve quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "309fbfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99224, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7bc2406110b926393aa56f80a40eba40</td>\n",
       "      <td>73fc7af87114b39712e6da79b0a377eb</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>2018-01-18 21:46:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80e641a11e56f04c1ad469d5645fdfde</td>\n",
       "      <td>a548910a1c6147796b98fdf73dbeba33</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-03-10</td>\n",
       "      <td>2018-03-11 03:05:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228ce5500dc1d8e020d8d1322874b6f0</td>\n",
       "      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-17</td>\n",
       "      <td>2018-02-18 14:36:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n",
       "      <td>658677c97b385a9be170737859d3511b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>2017-04-21 22:02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
       "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>2018-03-02 10:26:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id                          order_id  \\\n",
       "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
       "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
       "2  228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
       "3  e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
       "4  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
       "\n",
       "   review_score review_comment_title  \\\n",
       "0             4                  NaN   \n",
       "1             5                  NaN   \n",
       "2             5                  NaN   \n",
       "3             5                  NaN   \n",
       "4             5                  NaN   \n",
       "\n",
       "                              review_comment_message review_creation_date  \\\n",
       "0                                                NaN           2018-01-18   \n",
       "1                                                NaN           2018-03-10   \n",
       "2                                                NaN           2018-02-17   \n",
       "3              Recebi bem antes do prazo estipulado.           2017-04-21   \n",
       "4  Parabéns lojas lannister adorei comprar pela I...           2018-03-01   \n",
       "\n",
       "  review_answer_timestamp  \n",
       "0     2018-01-18 21:46:59  \n",
       "1     2018-03-11 03:05:13  \n",
       "2     2018-02-18 14:36:24  \n",
       "3     2017-04-21 22:02:06  \n",
       "4     2018-03-02 10:26:53  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99224 entries, 0 to 99223\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   review_id                99224 non-null  object        \n",
      " 1   order_id                 99224 non-null  object        \n",
      " 2   review_score             99224 non-null  int64         \n",
      " 3   review_comment_title     11568 non-null  object        \n",
      " 4   review_comment_message   40977 non-null  object        \n",
      " 5   review_creation_date     99224 non-null  datetime64[ns]\n",
      " 6   review_answer_timestamp  99224 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](2), int64(1), object(4)\n",
      "memory usage: 5.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "review_id                      0\n",
       "order_id                       0\n",
       "review_score                   0\n",
       "review_comment_title       87656\n",
       "review_comment_message     58247\n",
       "review_creation_date           0\n",
       "review_answer_timestamp        0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "review_id                  98410\n",
       "order_id                   98673\n",
       "review_score                   5\n",
       "review_comment_title        4527\n",
       "review_comment_message     36159\n",
       "review_creation_date         636\n",
       "review_answer_timestamp    98248\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(order_reviews.shape)\n",
    "display(order_reviews.head())\n",
    "display(order_reviews.info())\n",
    "display(order_reviews.isnull().sum())\n",
    "display(order_reviews.nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba61a82",
   "metadata": {},
   "source": [
    "### Order Reviews - Findings\n",
    "- `review_creation_date` and `review_answer_timestamp` need conversion from object to datetime.\n",
    "- Duplicate `review_id` entries may exist, and  hence need to checked and removed.\n",
    "- There are missing values in the columns (`review_comment_title` and `review_comment_message`).\n",
    "- Possible missing `review_score` (but should not be removed since not every customer leaves reviews for the items purchased).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f47312",
   "metadata": {},
   "source": [
    "### Order Reviews - Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d01da22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order reviews shape before cleaning: 99224\n"
     ]
    }
   ],
   "source": [
    "print(f\"order reviews shape before cleaning: {order_reviews.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a313d129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99224 entries, 0 to 99223\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   review_id                99224 non-null  object        \n",
      " 1   order_id                 99224 non-null  object        \n",
      " 2   review_score             99224 non-null  int64         \n",
      " 3   review_comment_title     11568 non-null  object        \n",
      " 4   review_comment_message   40977 non-null  object        \n",
      " 5   review_creation_date     99224 non-null  datetime64[ns]\n",
      " 6   review_answer_timestamp  99224 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](2), int64(1), object(4)\n",
      "memory usage: 5.3+ MB\n",
      "Duplicate review_id entries: 814\n"
     ]
    }
   ],
   "source": [
    "#Changing the dattype of timestamp columns to datetime\n",
    "date_cols = ['review_creation_date', 'review_answer_timestamp']\n",
    "for col in date_cols:\n",
    "    order_reviews[col] = pd.to_datetime(order_reviews[col], errors='coerce')\n",
    "\n",
    "#checking for missing review_id entries\n",
    "order_reviews['review_id'].isnull().sum()\n",
    "order_reviews.info()\n",
    "#checking for duplicate review_id entries\n",
    "order_reviews[order_reviews['order_id'].duplicated()]\n",
    "\n",
    "#printing number of duplicate review_id entries\n",
    "print(f\"Duplicate review_id entries: {order_reviews['review_id'].duplicated().sum()}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da7fefc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29841</th>\n",
       "      <td>00130cbe1f9d422698c812ed8ded1919</td>\n",
       "      <td>04a28263e085d399c97ae49e0b477efa</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O cartucho \"original HP\" 60XL não é reconhecid...</td>\n",
       "      <td>2018-03-07</td>\n",
       "      <td>2018-03-20 18:08:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46678</th>\n",
       "      <td>00130cbe1f9d422698c812ed8ded1919</td>\n",
       "      <td>dfcdfc43867d1c1381bfaf62d6b9c195</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O cartucho \"original HP\" 60XL não é reconhecid...</td>\n",
       "      <td>2018-03-07</td>\n",
       "      <td>2018-03-20 18:08:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              review_id                          order_id  \\\n",
       "29841  00130cbe1f9d422698c812ed8ded1919  04a28263e085d399c97ae49e0b477efa   \n",
       "46678  00130cbe1f9d422698c812ed8ded1919  dfcdfc43867d1c1381bfaf62d6b9c195   \n",
       "\n",
       "       review_score review_comment_title  \\\n",
       "29841             1                  NaN   \n",
       "46678             1                  NaN   \n",
       "\n",
       "                                  review_comment_message review_creation_date  \\\n",
       "29841  O cartucho \"original HP\" 60XL não é reconhecid...           2018-03-07   \n",
       "46678  O cartucho \"original HP\" 60XL não é reconhecid...           2018-03-07   \n",
       "\n",
       "      review_answer_timestamp  \n",
       "29841     2018-03-20 18:08:23  \n",
       "46678     2018-03-20 18:08:23  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Group by review_id to check uniqueness across orders and scores\n",
    "review_check = order_reviews.groupby('review_id').agg({\n",
    "    'order_id': 'nunique',\n",
    "    'review_score': 'nunique',\n",
    "    'review_creation_date': 'nunique'\n",
    "}).sort_values(by='order_id', ascending=False)\n",
    "\n",
    "review_check.head()\n",
    "\n",
    "# Reviews tied to multiple order_ids (shouldn't happen normally)\n",
    "suspicious_reviews = order_reviews.groupby('review_id').agg({\n",
    "    'order_id': 'nunique'\n",
    "})\n",
    "suspicious_reviews = suspicious_reviews[suspicious_reviews['order_id'] > 1]\n",
    "\n",
    "# Example: extract one suspicious review\n",
    "example_fake = order_reviews[order_reviews['review_id'] == suspicious_reviews.index[0]]\n",
    "example_fake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3f9e19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5adf08e34b2e993982a47070956c5c65</td>\n",
       "      <td>1175e95fb47ddff9de6b2b06188f7e0d</td>\n",
       "      <td>81560</td>\n",
       "      <td>curitiba</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>8891eb5ca0e28df961b2b5b8f3c0eb23</td>\n",
       "      <td>13ac6da47fef1b17b16f511e03b57918</td>\n",
       "      <td>2632</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>acca74d2a60c03b46a5256c02cef9244</td>\n",
       "      <td>f34cd7fd85a1f8baff886edf09567be3</td>\n",
       "      <td>89120</td>\n",
       "      <td>timbo</td>\n",
       "      <td>SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>46c6a82294d359a290ff408b11cbb643</td>\n",
       "      <td>1605a6c5d93d3488fb621c5323930795</td>\n",
       "      <td>22251</td>\n",
       "      <td>rio de janeiro</td>\n",
       "      <td>RJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>852947b57caab58c544343592f5e06d2</td>\n",
       "      <td>4f6d635ff2fd4e30ff5369a7b943eb22</td>\n",
       "      <td>8340</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99259</th>\n",
       "      <td>e625d447d6605488f6e7b8bba3024e08</td>\n",
       "      <td>0e3c753956e35026b965d9ac3590c5af</td>\n",
       "      <td>28013</td>\n",
       "      <td>campos dos goytacazes</td>\n",
       "      <td>RJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99264</th>\n",
       "      <td>ff09fd7b29e7488a8d8a20badcd8befe</td>\n",
       "      <td>8c21dd8c37144807c601f99f2a209dfb</td>\n",
       "      <td>72587</td>\n",
       "      <td>brasilia</td>\n",
       "      <td>DF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99320</th>\n",
       "      <td>4740044a9390cc45b2c213e8714129e7</td>\n",
       "      <td>08f7cf00ed9ff3e0a08fc136ec272974</td>\n",
       "      <td>71900</td>\n",
       "      <td>brasilia</td>\n",
       "      <td>DF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99324</th>\n",
       "      <td>5b46a0d983eec8c97363bea78d4a69dd</td>\n",
       "      <td>8bab3162259edfaadd1ea2e1fe7f58dc</td>\n",
       "      <td>31565</td>\n",
       "      <td>belo horizonte</td>\n",
       "      <td>MG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99327</th>\n",
       "      <td>c1affa46f9f3b514555259049a0307b9</td>\n",
       "      <td>12ab9334b1240d6d037f2b0102a49571</td>\n",
       "      <td>38050</td>\n",
       "      <td>uberaba</td>\n",
       "      <td>MG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1412 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            customer_id                customer_unique_id  \\\n",
       "8      5adf08e34b2e993982a47070956c5c65  1175e95fb47ddff9de6b2b06188f7e0d   \n",
       "113    8891eb5ca0e28df961b2b5b8f3c0eb23  13ac6da47fef1b17b16f511e03b57918   \n",
       "134    acca74d2a60c03b46a5256c02cef9244  f34cd7fd85a1f8baff886edf09567be3   \n",
       "187    46c6a82294d359a290ff408b11cbb643  1605a6c5d93d3488fb621c5323930795   \n",
       "199    852947b57caab58c544343592f5e06d2  4f6d635ff2fd4e30ff5369a7b943eb22   \n",
       "...                                 ...                               ...   \n",
       "99259  e625d447d6605488f6e7b8bba3024e08  0e3c753956e35026b965d9ac3590c5af   \n",
       "99264  ff09fd7b29e7488a8d8a20badcd8befe  8c21dd8c37144807c601f99f2a209dfb   \n",
       "99320  4740044a9390cc45b2c213e8714129e7  08f7cf00ed9ff3e0a08fc136ec272974   \n",
       "99324  5b46a0d983eec8c97363bea78d4a69dd  8bab3162259edfaadd1ea2e1fe7f58dc   \n",
       "99327  c1affa46f9f3b514555259049a0307b9  12ab9334b1240d6d037f2b0102a49571   \n",
       "\n",
       "       customer_zip_code_prefix          customer_city customer_state  \n",
       "8                         81560               curitiba             PR  \n",
       "113                        2632              sao paulo             SP  \n",
       "134                       89120                  timbo             SC  \n",
       "187                       22251         rio de janeiro             RJ  \n",
       "199                        8340              sao paulo             SP  \n",
       "...                         ...                    ...            ...  \n",
       "99259                     28013  campos dos goytacazes             RJ  \n",
       "99264                     72587               brasilia             DF  \n",
       "99320                     71900               brasilia             DF  \n",
       "99324                     31565         belo horizonte             MG  \n",
       "99327                     38050                uberaba             MG  \n",
       "\n",
       "[1412 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find customers who made these suspicious reviews\n",
    "fake_review_ids = suspicious_reviews.index\n",
    "fake_orders = order_reviews[order_reviews['review_id'].isin(fake_review_ids)]['order_id']\n",
    "fake_customers = orders[orders['order_id'].isin(fake_orders)]['customer_id']\n",
    "customers[customers['customer_id'].isin(fake_customers)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb7c6209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98410, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Keep only the first review_id occurrence\n",
    "order_reviews_cleaned = order_reviews.drop_duplicates(subset=['review_id'], keep='first')\n",
    "display(order_reviews_cleaned.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3f105c",
   "metadata": {},
   "source": [
    "### 6. Products\n",
    "The products table contains details of items sold. Typical columns are:\n",
    "- product_id → Unique identifier of the product.\n",
    "- product_category_name → Category of the product (in Portuguese).\n",
    "- product_name_lenght, product_description_lenght, product_photos_qty → Metadata about product listings.\n",
    "- product_weight_g, product_length_cm, product_height_cm, product_width_cm → Dimensions and weight for shipping\n",
    "\n",
    "We will explore this dataset to find any issues with structure and to improve quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef13ba67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32951, 9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_name_lenght</th>\n",
       "      <th>product_description_lenght</th>\n",
       "      <th>product_photos_qty</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>product_length_cm</th>\n",
       "      <th>product_height_cm</th>\n",
       "      <th>product_width_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1e9e8ef04dbcff4541ed26657ea517e5</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>40.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3aa071139cb16b67ca9e5dea641aaa2f</td>\n",
       "      <td>artes</td>\n",
       "      <td>44.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96bd76ec8810374ed1b65e291975717f</td>\n",
       "      <td>esporte_lazer</td>\n",
       "      <td>46.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cef67bcfe19066a932b7673e239eb23d</td>\n",
       "      <td>bebes</td>\n",
       "      <td>27.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9dc1a7de274444849c219cff195d0b71</td>\n",
       "      <td>utilidades_domesticas</td>\n",
       "      <td>37.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         product_id  product_category_name  \\\n",
       "0  1e9e8ef04dbcff4541ed26657ea517e5             perfumaria   \n",
       "1  3aa071139cb16b67ca9e5dea641aaa2f                  artes   \n",
       "2  96bd76ec8810374ed1b65e291975717f          esporte_lazer   \n",
       "3  cef67bcfe19066a932b7673e239eb23d                  bebes   \n",
       "4  9dc1a7de274444849c219cff195d0b71  utilidades_domesticas   \n",
       "\n",
       "   product_name_lenght  product_description_lenght  product_photos_qty  \\\n",
       "0                 40.0                       287.0                 1.0   \n",
       "1                 44.0                       276.0                 1.0   \n",
       "2                 46.0                       250.0                 1.0   \n",
       "3                 27.0                       261.0                 1.0   \n",
       "4                 37.0                       402.0                 4.0   \n",
       "\n",
       "   product_weight_g  product_length_cm  product_height_cm  product_width_cm  \n",
       "0             225.0               16.0               10.0              14.0  \n",
       "1            1000.0               30.0               18.0              20.0  \n",
       "2             154.0               18.0                9.0              15.0  \n",
       "3             371.0               26.0                4.0              26.0  \n",
       "4             625.0               20.0               17.0              13.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32951 entries, 0 to 32950\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   product_id                  32951 non-null  object \n",
      " 1   product_category_name       32341 non-null  object \n",
      " 2   product_name_lenght         32341 non-null  float64\n",
      " 3   product_description_lenght  32341 non-null  float64\n",
      " 4   product_photos_qty          32341 non-null  float64\n",
      " 5   product_weight_g            32949 non-null  float64\n",
      " 6   product_length_cm           32949 non-null  float64\n",
      " 7   product_height_cm           32949 non-null  float64\n",
      " 8   product_width_cm            32949 non-null  float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "product_id                      0\n",
       "product_category_name         610\n",
       "product_name_lenght           610\n",
       "product_description_lenght    610\n",
       "product_photos_qty            610\n",
       "product_weight_g                2\n",
       "product_length_cm               2\n",
       "product_height_cm               2\n",
       "product_width_cm                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(products.shape)\n",
    "display(products.head())\n",
    "display(products.info())\n",
    "products.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5c6f92",
   "metadata": {},
   "source": [
    "### Product - Findings\n",
    "- Column names are not standardized, hence needs renaming.\n",
    "- `product_category_name` has missing values so drop those rows.\n",
    "- Few missing values in weight, height, length, width → impute using median (better than mean since it handles skew).\n",
    "- Other values are valid, no duplicates or major anomalies detected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33e52ad",
   "metadata": {},
   "source": [
    "### Products - Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d59eb59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing product_category_name rows: 610\n",
      "Missing categories which is : 1.85%\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32341 entries, 0 to 32340\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   product_id                  32341 non-null  object \n",
      " 1   product_category_name       32341 non-null  object \n",
      " 2   product_name_length         32341 non-null  float64\n",
      " 3   product_description_lenght  32341 non-null  float64\n",
      " 4   product_photos_qty          32341 non-null  float64\n",
      " 5   product_weight_g            32340 non-null  float64\n",
      " 6   product_length_cm           32340 non-null  float64\n",
      " 7   product_height_cm           32340 non-null  float64\n",
      " 8   product_width_cm            32340 non-null  float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#renaming columns to standardize\n",
    "products.rename(columns = {'product_name_lenght': 'product_name_length', 'product_description_lenght ': 'product_description_length'}, inplace=True)\n",
    "\n",
    "#Checking for missing product_category_name values\n",
    "missing_category = products[products['product_category_name'].isna()]\n",
    "print(f\"Missing product_category_name rows: {missing_category.shape[0]}\")\n",
    "missing_category_ratio = products['product_category_name'].isna().mean() * 100\n",
    "print(f\"Missing categories which is : {missing_category_ratio:.2f}%\")\n",
    "#Dropping rows with missing product_category_name\n",
    "products_cleaned= products.dropna(subset=['product_category_name']).reset_index(drop=True)\n",
    "products_cleaned.info()\n",
    "\n",
    "product_names_unq= products_cleaned['product_category_name'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86db40da",
   "metadata": {},
   "source": [
    "### 7. Sellers\n",
    "The sellers dataset provides information about the marketplace sellers (vendors) who list products on the Olist platform.\n",
    "\n",
    "Columns:\n",
    "- seller_id → Unique identifier for each seller.\n",
    "- seller_zip_code_prefix → First 5 digits of the seller’s ZIP code.\n",
    "- seller_city → City where the seller is located.\n",
    "- seller_state → State where the seller is located (two-letter abbreviation, e.g., SP, RJ).\n",
    "\n",
    "We will further explore dataset to find any issue with the stucture of the dataset or to improve quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e78e32da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3095, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seller_id</th>\n",
       "      <th>seller_zip_code_prefix</th>\n",
       "      <th>seller_city</th>\n",
       "      <th>seller_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3442f8959a84dea7ee197c632cb2df15</td>\n",
       "      <td>13023</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d1b65fc7debc3361ea86b5f14c68d2e2</td>\n",
       "      <td>13844</td>\n",
       "      <td>mogi guacu</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce3ad9de960102d0677a81f5d0bb7b2d</td>\n",
       "      <td>20031</td>\n",
       "      <td>rio de janeiro</td>\n",
       "      <td>RJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c0f3eea2e14555b6faeea3dd58c1b1c3</td>\n",
       "      <td>4195</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51a04a8a6bdcb23deccc82b0b80742cf</td>\n",
       "      <td>12914</td>\n",
       "      <td>braganca paulista</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c240c4061717ac1806ae6ee72be3533b</td>\n",
       "      <td>20920</td>\n",
       "      <td>rio de janeiro</td>\n",
       "      <td>RJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e49c26c3edfa46d227d5121a6b6e4d37</td>\n",
       "      <td>55325</td>\n",
       "      <td>brejao</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1b938a7ec6ac5061a66a3766e0e75f90</td>\n",
       "      <td>16304</td>\n",
       "      <td>penapolis</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>768a86e36ad6aae3d03ee3c6433d61df</td>\n",
       "      <td>1529</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ccc4bbb5f32a6ab2b7066a4130f114e3</td>\n",
       "      <td>80310</td>\n",
       "      <td>curitiba</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          seller_id  seller_zip_code_prefix  \\\n",
       "0  3442f8959a84dea7ee197c632cb2df15                   13023   \n",
       "1  d1b65fc7debc3361ea86b5f14c68d2e2                   13844   \n",
       "2  ce3ad9de960102d0677a81f5d0bb7b2d                   20031   \n",
       "3  c0f3eea2e14555b6faeea3dd58c1b1c3                    4195   \n",
       "4  51a04a8a6bdcb23deccc82b0b80742cf                   12914   \n",
       "5  c240c4061717ac1806ae6ee72be3533b                   20920   \n",
       "6  e49c26c3edfa46d227d5121a6b6e4d37                   55325   \n",
       "7  1b938a7ec6ac5061a66a3766e0e75f90                   16304   \n",
       "8  768a86e36ad6aae3d03ee3c6433d61df                    1529   \n",
       "9  ccc4bbb5f32a6ab2b7066a4130f114e3                   80310   \n",
       "\n",
       "         seller_city seller_state  \n",
       "0           campinas           SP  \n",
       "1         mogi guacu           SP  \n",
       "2     rio de janeiro           RJ  \n",
       "3          sao paulo           SP  \n",
       "4  braganca paulista           SP  \n",
       "5     rio de janeiro           RJ  \n",
       "6             brejao           PE  \n",
       "7          penapolis           SP  \n",
       "8          sao paulo           SP  \n",
       "9           curitiba           PR  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3095 entries, 0 to 3094\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   seller_id               3095 non-null   object\n",
      " 1   seller_zip_code_prefix  3095 non-null   int64 \n",
      " 2   seller_city             3095 non-null   object\n",
      " 3   seller_state            3095 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 96.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "seller_state\n",
       "SP    1849\n",
       "PR     349\n",
       "MG     244\n",
       "SC     190\n",
       "RJ     171\n",
       "RS     129\n",
       "GO      40\n",
       "DF      30\n",
       "ES      23\n",
       "BA      19\n",
       "CE      13\n",
       "PE       9\n",
       "PB       6\n",
       "RN       5\n",
       "MS       5\n",
       "MT       4\n",
       "RO       2\n",
       "SE       2\n",
       "PI       1\n",
       "AC       1\n",
       "MA       1\n",
       "AM       1\n",
       "PA       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "seller_city\n",
       "sao paulo              694\n",
       "curitiba               127\n",
       "rio de janeiro          96\n",
       "belo horizonte          68\n",
       "ribeirao preto          52\n",
       "                      ... \n",
       "taruma                   1\n",
       "s jose do rio preto      1\n",
       "domingos martins         1\n",
       "messias targino          1\n",
       "leme                     1\n",
       "Name: count, Length: 611, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sellers.shape)\n",
    "display(sellers.head(10))\n",
    "display(sellers.info())\n",
    "print(sellers['seller_id'].duplicated().sum())\n",
    "display(sellers['seller_state'].value_counts())\n",
    "display(sellers['seller_city'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c09ca08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seller_state</th>\n",
       "      <th>seller_city</th>\n",
       "      <th>num_cities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AC</td>\n",
       "      <td>[rio branco]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AM</td>\n",
       "      <td>[manaus]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BA</td>\n",
       "      <td>[lauro de freitas, porto seguro, salvador, bar...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CE</td>\n",
       "      <td>[fortaleza, mucambo, pacatuba, juzeiro do nort...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF</td>\n",
       "      <td>[brasilia, brasilia df, gama]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seller_state                                        seller_city  num_cities\n",
       "0           AC                                       [rio branco]           1\n",
       "1           AM                                           [manaus]           1\n",
       "2           BA  [lauro de freitas, porto seguro, salvador, bar...          12\n",
       "3           CE  [fortaleza, mucambo, pacatuba, juzeiro do nort...           7\n",
       "4           DF                      [brasilia, brasilia df, gama]           3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group cities by state and list unique cities for each\n",
    "cities_per_state = sellers.groupby('seller_state')['seller_city'].unique().reset_index()\n",
    "\n",
    "# Optional: see how many unique cities per state\n",
    "cities_per_state['num_cities'] = cities_per_state['seller_city'].apply(len)\n",
    "\n",
    "cities_per_state.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9d796b",
   "metadata": {},
   "source": [
    "### Sellers - Findings\n",
    "- There are no missing values in the sellers dataset.\n",
    "- Each seller is uniquely identified by `seller_id`.\n",
    "- We need to standardize the `seller_city` names.\n",
    "- There are inconsistencies in `seller_city` values (e.g., \"brasilia\" and \"brasilia df\" represent the same city but are written differently). Similar cases exist for other cities as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9c2a7c",
   "metadata": {},
   "source": [
    "### Sellers - Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1906875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in ./.venv/lib/python3.13/site-packages (1.4.0)\n"
     ]
    }
   ],
   "source": [
    "# Handling accented and unicode characters and for that importing unidecode.\n",
    "!pip install unidecode\n",
    "from unidecode import unidecode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5606fb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicate cities : 2486\n"
     ]
    }
   ],
   "source": [
    "# Standardize city names to lower case\n",
    "sellers['seller_city'] = sellers['seller_city'].str.lower().str.strip()\n",
    "# Remove accents and special characters\n",
    "sellers['seller_city'] = sellers['seller_city'].apply(lambda x: unidecode(x))\n",
    "#checking for the duplicates now\n",
    "print(f\"Total duplicate cities : {sellers['seller_city'].duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a48da237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['04482255',\n",
       " 'abadia de goias',\n",
       " 'afonso claudio',\n",
       " 'aguas claras df',\n",
       " 'alambari',\n",
       " 'almirante tamandare',\n",
       " 'alvares machado',\n",
       " 'alvorada',\n",
       " 'ampere',\n",
       " 'andira-pr',\n",
       " 'angra dos reis',\n",
       " 'angra dos reis rj',\n",
       " 'ao bernardo do campo',\n",
       " 'aparecida',\n",
       " 'aparecida de goiania',\n",
       " 'aperibe',\n",
       " 'aracaju',\n",
       " 'araquari',\n",
       " 'ararangua',\n",
       " 'arinos',\n",
       " \"arraial d'ajuda (porto seguro)\",\n",
       " 'arvorezinha',\n",
       " 'auriflama',\n",
       " 'auriflama/sp',\n",
       " 'avare',\n",
       " 'bage',\n",
       " 'bahia',\n",
       " 'balenario camboriu',\n",
       " 'bandeirantes',\n",
       " 'barbacena',\n",
       " 'barbacena/ minas gerais',\n",
       " 'barra velha',\n",
       " 'barrinha',\n",
       " 'barro alto',\n",
       " 'bebedouro',\n",
       " 'belo horizont',\n",
       " 'bertioga',\n",
       " 'bocaiuva do sul',\n",
       " 'bofete',\n",
       " 'bom jardim',\n",
       " 'bom jesus dos perdoes',\n",
       " 'bombinhas',\n",
       " 'bonfinopolis de minas',\n",
       " 'braco do norte',\n",
       " 'brasilia df',\n",
       " 'brejao',\n",
       " 'brotas',\n",
       " 'buritama',\n",
       " 'cacador',\n",
       " 'cachoeira do sul',\n",
       " 'caieiras',\n",
       " 'california',\n",
       " 'camanducaia',\n",
       " 'camboriu',\n",
       " 'campanha',\n",
       " 'campina das missoes',\n",
       " 'campina grande',\n",
       " 'campo do meio',\n",
       " 'campo magro',\n",
       " 'campo mourao',\n",
       " 'campos dos goytacazes',\n",
       " 'campos novos',\n",
       " 'cananeia',\n",
       " 'carapicuiba / sao paulo',\n",
       " 'caratinga',\n",
       " 'cariacica / es',\n",
       " 'carmo da mata',\n",
       " 'carmo do cajuru',\n",
       " 'cascavael',\n",
       " 'castro pires',\n",
       " 'cataguases',\n",
       " 'caucaia',\n",
       " 'centro',\n",
       " 'cerqueira cesar',\n",
       " 'cianorte',\n",
       " 'clementina',\n",
       " 'colatina',\n",
       " 'colorado',\n",
       " 'concordia',\n",
       " 'condor',\n",
       " 'congonhal',\n",
       " 'congonhas',\n",
       " 'cordeiropolis',\n",
       " 'cordilheira alta',\n",
       " 'cornelio procopio',\n",
       " 'coxim',\n",
       " 'cravinhos',\n",
       " 'cruzeiro',\n",
       " 'descalvado',\n",
       " 'divisa nova',\n",
       " 'domingos martins',\n",
       " 'dracena',\n",
       " 'embu guacu',\n",
       " 'engenheiro coelho',\n",
       " 'entre rios do oeste',\n",
       " 'erechim',\n",
       " 'eunapolis',\n",
       " 'eusebio',\n",
       " 'extrema',\n",
       " 'feira de santana',\n",
       " 'fernando prestes',\n",
       " 'ferraz de  vasconcelos',\n",
       " 'floranopolis',\n",
       " 'floresta',\n",
       " 'formosa do oeste',\n",
       " 'francisco morato',\n",
       " 'fronteira',\n",
       " 'gama',\n",
       " 'garulhos',\n",
       " 'garuva',\n",
       " 'goioere',\n",
       " 'governador valadares',\n",
       " 'guaimbe',\n",
       " 'guanambi',\n",
       " 'guanhaes',\n",
       " 'guara',\n",
       " 'guarapuava',\n",
       " 'guaratingueta',\n",
       " 'guariba',\n",
       " 'guiricema',\n",
       " 'holambra',\n",
       " 'horizontina',\n",
       " 'ibia',\n",
       " 'ibirite',\n",
       " 'icara',\n",
       " 'igrejinha',\n",
       " 'ilheus',\n",
       " 'ilicinea',\n",
       " 'imbe',\n",
       " 'imbituva',\n",
       " 'imigrante',\n",
       " 'ipaussu',\n",
       " 'ipe',\n",
       " 'ipua',\n",
       " 'irati',\n",
       " 'irece',\n",
       " 'itabira',\n",
       " 'itaborai',\n",
       " 'itapema',\n",
       " 'itapeva',\n",
       " 'itaporanga',\n",
       " 'itapui',\n",
       " 'itau de minas',\n",
       " 'itirapina',\n",
       " 'ivoti',\n",
       " 'jacarei / sao paulo',\n",
       " 'jaciara',\n",
       " 'jales',\n",
       " 'jambeiro',\n",
       " 'janauba',\n",
       " 'japira',\n",
       " 'jaragua',\n",
       " 'jarinu',\n",
       " 'ji parana',\n",
       " 'joao monlevade',\n",
       " 'joao pinheiro',\n",
       " 'jussara',\n",
       " 'juzeiro do norte',\n",
       " 'lages - sc',\n",
       " 'lagoa santa',\n",
       " 'laguna',\n",
       " 'lambari',\n",
       " 'laranjeiras do sul',\n",
       " 'leme',\n",
       " 'louveira',\n",
       " 'luiz alves',\n",
       " 'luziania',\n",
       " 'macatuba',\n",
       " 'mage',\n",
       " 'mairinque',\n",
       " 'mamanguape',\n",
       " 'manaus',\n",
       " 'mandaguacu',\n",
       " 'mandaguari',\n",
       " 'mandirituba',\n",
       " 'marapoama',\n",
       " 'marialva',\n",
       " 'marica',\n",
       " 'massaranduba',\n",
       " 'mateus leme',\n",
       " 'maua/sao paulo',\n",
       " 'medianeira',\n",
       " 'messias targino',\n",
       " 'miguelopolis',\n",
       " 'minas gerais',\n",
       " 'mineiros do tiete',\n",
       " 'mirandopolis',\n",
       " 'mococa',\n",
       " 'mogi das cruses',\n",
       " 'mogi das cruzes / sp',\n",
       " 'mombuca',\n",
       " 'monte alegre do sul',\n",
       " 'monte alto',\n",
       " 'monte siao',\n",
       " 'monteiro lobato',\n",
       " 'mucambo',\n",
       " 'muqui',\n",
       " 'muriae',\n",
       " 'neopolis',\n",
       " 'nhandeara',\n",
       " 'nova lima',\n",
       " 'nova petropolis',\n",
       " 'nova trento',\n",
       " 'novo hamburgo, rio grande do sul, brasil',\n",
       " 'novo horizonte',\n",
       " 'olimpia',\n",
       " 'oliveira',\n",
       " 'orlandia',\n",
       " 'orleans',\n",
       " 'ourinhos',\n",
       " 'ouro fino',\n",
       " 'ouro preto',\n",
       " 'pacatuba',\n",
       " 'paincandu',\n",
       " 'palotina',\n",
       " 'paracambi',\n",
       " 'parai',\n",
       " 'paraiba do sul',\n",
       " 'paraiso do sul',\n",
       " 'parana',\n",
       " 'paranavai',\n",
       " 'parnamirim',\n",
       " 'passos',\n",
       " 'pato bragado',\n",
       " 'pederneiras',\n",
       " 'pedregulho',\n",
       " 'pedrinhas paulista',\n",
       " 'pedro leopoldo',\n",
       " 'picarras',\n",
       " 'pilar do sul',\n",
       " 'pinhais/pr',\n",
       " 'pinhalao',\n",
       " 'piracanjuba',\n",
       " 'pirassununga',\n",
       " 'pirituba',\n",
       " 'pitangueiras',\n",
       " 'poa',\n",
       " 'ponte nova',\n",
       " 'portao',\n",
       " 'porto seguro',\n",
       " 'porto velho',\n",
       " 'portoferreira',\n",
       " 'pouso alegre',\n",
       " 'prados',\n",
       " 'presidente bernardes',\n",
       " 'presidente epitacio',\n",
       " 'presidente getulio',\n",
       " 'queimados',\n",
       " 'resende',\n",
       " 'ribeirao preto / sao paulo',\n",
       " 'ribeirao pretp',\n",
       " 'riberao preto',\n",
       " 'rio branco',\n",
       " 'rio das pedras',\n",
       " 'rio de janeiro / rio de janeiro',\n",
       " 'rio de janeiro \\\\rio de janeiro',\n",
       " 'rio de janeiro, rio de janeiro, brasil',\n",
       " 'rio do oeste',\n",
       " 'rio grande',\n",
       " 'rio negrinho',\n",
       " 'rio verde',\n",
       " 'robeirao preto',\n",
       " 'rolante',\n",
       " 'ronda alta',\n",
       " 's jose do rio preto',\n",
       " 'sabara',\n",
       " 'sando andre',\n",
       " 'santa barbara d oeste',\n",
       " 'santa catarina',\n",
       " 'santa cecilia',\n",
       " 'santa cruz do sul',\n",
       " 'santa maria da serra',\n",
       " 'santa rosa de viterbo',\n",
       " 'santa terezinha de goias',\n",
       " 'santo andre/sao paulo',\n",
       " 'santo angelo',\n",
       " 'santo antonio da patrulha',\n",
       " 'santo antonio de padua',\n",
       " 'santo antonio de posse',\n",
       " 'sao  jose dos pinhais',\n",
       " 'sao  paulo',\n",
       " 'sao bento',\n",
       " 'sao bernardo do capo',\n",
       " 'sao francisco do sul',\n",
       " 'sao joao da boa vista',\n",
       " 'sao joaquim da barra',\n",
       " 'sao jose do rio pret',\n",
       " 'sao jose dos pinhas',\n",
       " 'sao luis',\n",
       " \"sao miguel d'oeste\",\n",
       " 'sao miguel do oeste',\n",
       " 'sao paluo',\n",
       " 'sao paulo / sao paulo',\n",
       " 'sao paulo sp',\n",
       " 'sao paulop',\n",
       " 'sao pauo',\n",
       " 'sao pedro da aldeia',\n",
       " 'sao sebastiao',\n",
       " 'sao sebastiao da grama/sp',\n",
       " 'sao vicente',\n",
       " 'sapiranga',\n",
       " 'saquarema',\n",
       " 'sbc',\n",
       " 'sbc/sp',\n",
       " 'scao jose do rio pardo',\n",
       " 'serra redonda',\n",
       " 'serrana',\n",
       " 'sertanopolis',\n",
       " 'sinop',\n",
       " 'socorro',\n",
       " 'soledade',\n",
       " 'sp / sp',\n",
       " 'tabao da serra',\n",
       " 'taio',\n",
       " 'tambau',\n",
       " 'taruma',\n",
       " 'teixeira soares',\n",
       " 'teresina',\n",
       " 'terra boa',\n",
       " 'tiete',\n",
       " 'timoteo',\n",
       " 'tocantins',\n",
       " 'torres',\n",
       " 'tres coroas',\n",
       " 'tres de maio',\n",
       " 'tres rios',\n",
       " 'triunfo',\n",
       " 'ubatuba',\n",
       " 'uniao da vitoria',\n",
       " 'uruguaiana',\n",
       " 'vargem grande paulista',\n",
       " 'varzea alegre',\n",
       " 'varzea paulista',\n",
       " 'vassouras',\n",
       " 'vendas@creditparts.com.br',\n",
       " 'vera cruz',\n",
       " 'vespasiano',\n",
       " 'viana',\n",
       " 'vicente de carvalho',\n",
       " 'vitoria de santo antao',\n",
       " 'xaxim']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_entry_cities = sellers['seller_city'].value_counts()[sellers['seller_city'].value_counts() == 1]\n",
    "sorted(single_entry_cities.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87b4947c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seller_city\n",
       "sao paulo         707\n",
       "curitiba          127\n",
       "rio de janeiro     99\n",
       "belo horizonte     68\n",
       "ribeirao preto     52\n",
       "                 ... \n",
       "nhandeara           1\n",
       "guarapuava          1\n",
       "sinop               1\n",
       "joao pinheiro       1\n",
       "leme                1\n",
       "Name: count, Length: 595, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Manually creating a mapping dictionary for city name corrections\n",
    "city_corrections = {\n",
    "    'sao pau': 'sao paulo',\n",
    "    'rio de janei': 'rio de janeiro',\n",
    "    'sao miguel' : \"sao miguel d'eoste\",\n",
    "    'santa antoni': 'santa antonia'\n",
    "}\n",
    "for wrong, correct in city_corrections.items():\n",
    "    sellers.loc[sellers['seller_city'].str.contains(wrong, case=False, na=False), 'seller_city'] = correct\n",
    "display(sellers['seller_city'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cd99d2",
   "metadata": {},
   "source": [
    "### 8. Geolocation\n",
    "This dataset contains information about customer/seller addresses:\n",
    "- geolocation_zip_code_prefix – shared with customers & sellers tables\n",
    "- geolocation_lat, geolocation_lng – latitude and longitude\n",
    "- geolocation_city – city name\n",
    "- geolocation_state – state code (2-letter)\n",
    "\n",
    "We will explore this dataset to standardize it and to improve quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8077d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000163, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geolocation_zip_code_prefix</th>\n",
       "      <th>geolocation_lat</th>\n",
       "      <th>geolocation_lng</th>\n",
       "      <th>geolocation_city</th>\n",
       "      <th>geolocation_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1037</td>\n",
       "      <td>-23.545621</td>\n",
       "      <td>-46.639292</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046</td>\n",
       "      <td>-23.546081</td>\n",
       "      <td>-46.644820</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1046</td>\n",
       "      <td>-23.546129</td>\n",
       "      <td>-46.642951</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1041</td>\n",
       "      <td>-23.544392</td>\n",
       "      <td>-46.639499</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1035</td>\n",
       "      <td>-23.541578</td>\n",
       "      <td>-46.641607</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geolocation_zip_code_prefix  geolocation_lat  geolocation_lng  \\\n",
       "0                         1037       -23.545621       -46.639292   \n",
       "1                         1046       -23.546081       -46.644820   \n",
       "2                         1046       -23.546129       -46.642951   \n",
       "3                         1041       -23.544392       -46.639499   \n",
       "4                         1035       -23.541578       -46.641607   \n",
       "\n",
       "  geolocation_city geolocation_state  \n",
       "0        sao paulo                SP  \n",
       "1        sao paulo                SP  \n",
       "2        sao paulo                SP  \n",
       "3        sao paulo                SP  \n",
       "4        sao paulo                SP  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000163 entries, 0 to 1000162\n",
      "Data columns (total 5 columns):\n",
      " #   Column                       Non-Null Count    Dtype  \n",
      "---  ------                       --------------    -----  \n",
      " 0   geolocation_zip_code_prefix  1000163 non-null  int64  \n",
      " 1   geolocation_lat              1000163 non-null  float64\n",
      " 2   geolocation_lng              1000163 non-null  float64\n",
      " 3   geolocation_city             1000163 non-null  object \n",
      " 4   geolocation_state            1000163 non-null  object \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 38.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "geolocation_zip_code_prefix     19015\n",
       "geolocation_lat                717363\n",
       "geolocation_lng                717615\n",
       "geolocation_city                 8011\n",
       "geolocation_state                  27\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(geoloc.shape)\n",
    "display(geoloc.head())\n",
    "display(geoloc.info())\n",
    "geoloc.isnull().sum()\n",
    "geoloc.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6c32c5",
   "metadata": {},
   "source": [
    "### Geolocation - Findings\n",
    "- This dataset has not missing values.\n",
    "- `geolocation_zip_code_prefix` is common to many locations with slightly varying latitude and longitudes. Repeated coordinated adds no value to our analysis. So, we will aggregate the zip code to get mean coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cff47ca",
   "metadata": {},
   "source": [
    "### Geolocation - Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6bb37a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before aggregation: (1000163, 5)\n",
      "After aggregation: (19015, 5)\n"
     ]
    }
   ],
   "source": [
    "# Aggregate geolocation by zip code prefix\n",
    "geo_agg = (\n",
    "    geoloc.groupby('geolocation_zip_code_prefix')\n",
    "    .agg({\n",
    "        'geolocation_lat': 'mean',   # average latitude\n",
    "        'geolocation_lng': 'mean',   # average longitude\n",
    "        'geolocation_city': lambda x: x.mode()[0] if not x.mode().empty else x.iloc[0],\n",
    "        'geolocation_state': lambda x: x.mode()[0] if not x.mode().empty else x.iloc[0]\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"Before aggregation:\", geoloc.shape)\n",
    "print(\"After aggregation:\", geo_agg.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dedff6",
   "metadata": {},
   "source": [
    "### 9. Product Category Name Transalation\n",
    "It provides translations of product category names from Portuguese to English.\n",
    "Columns:\n",
    "- product_category_name → in Portuguese\n",
    "- product_category_name_english → in English\n",
    "\n",
    "Lets Explore this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "916fe807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_category_name_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beleza_saude</td>\n",
       "      <td>health_beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>informatica_acessorios</td>\n",
       "      <td>computers_accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>automotivo</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cama_mesa_banho</td>\n",
       "      <td>bed_bath_table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moveis_decoracao</td>\n",
       "      <td>furniture_decor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_category_name product_category_name_english\n",
       "0            beleza_saude                 health_beauty\n",
       "1  informatica_acessorios         computers_accessories\n",
       "2              automotivo                          auto\n",
       "3         cama_mesa_banho                bed_bath_table\n",
       "4        moveis_decoracao               furniture_decor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71 entries, 0 to 70\n",
      "Data columns (total 2 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   product_category_name          71 non-null     object\n",
      " 1   product_category_name_english  71 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "product_category_name            0\n",
       "product_category_name_english    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(category_name_translation.shape)\n",
    "display(category_name_translation.head())\n",
    "display(category_name_translation.info())\n",
    "category_name_translation.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc8f55e",
   "metadata": {},
   "source": [
    "### Product Category Name Translation - Findings\n",
    "- Contains Portuguese category names with their English translations.  \n",
    "- Useful for making product data easier to analyze in English.  \n",
    "- Steps:\n",
    "  - No missing or null translations.  \n",
    "  - Ensure unique mapping between Portuguese and English categories.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91330f2",
   "metadata": {},
   "source": [
    "### Product Category Name Translation - Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d307794b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 73 entries, 0 to 72\n",
      "Data columns (total 2 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   product_category_name          73 non-null     object\n",
      " 1   product_category_name_english  73 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.3+ KB\n",
      "Missing categories: set()\n"
     ]
    }
   ],
   "source": [
    "category_name_translation.info()\n",
    "product_names_eng = category_name_translation['product_category_name'].unique()\n",
    "\n",
    "# Re-check for any missing categories\n",
    "missing_names = set(product_names_unq) - set(category_name_translation['product_category_name'])\n",
    "print(\"Missing categories:\", missing_names)\n",
    "\n",
    "missing_names_df = products[products['product_category_name'].isin(missing_names)]\n",
    "missing_names_df\n",
    "\n",
    "new_row = pd.DataFrame({\n",
    "    'product_category_name': ['portateis_cozinha_e_preparadores_de_alimentos', 'pc_gamer'], \n",
    "    'product_category_name_english': ['portable_kitchen_and_food_preparers', 'pc_gamer']})\n",
    "category_name_translation = pd.concat([category_name_translation, new_row], ignore_index=True)\n",
    "\n",
    "# Ensure no duplicate categories remain after adding new translations\n",
    "category_name_translation= category_name_translation.drop_duplicates(subset=['product_category_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a339401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers saved ✅\n",
      "orders saved ✅\n",
      "order_items saved ✅\n",
      "order_payments saved ✅\n",
      "order_reviews saved ✅\n",
      "products saved ✅\n",
      "sellers saved ✅\n",
      "geolocation saved ✅\n",
      "category_name_translation saved ✅\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create folder if it doesn't exist\n",
    "os.makedirs('cleaned_data', exist_ok=True)\n",
    "\n",
    "# Dictionary to mark which datasets are cleaned\n",
    "cleaned_status = {\n",
    "    'customers': True,\n",
    "    'orders': True,\n",
    "    'order_items': True,\n",
    "    'order_payments': True,\n",
    "    'order_reviews': True,\n",
    "    'products': True,\n",
    "    'sellers': True,\n",
    "    'geolocation': True,\n",
    "    'category_name_translation': True\n",
    "}\n",
    "\n",
    "# Dictionary of dataset variables\n",
    "datasets = {\n",
    "    'customers': customers,\n",
    "    'orders': orders_cleaned,\n",
    "    'order_items': order_items,\n",
    "    'order_payments': order_payments,\n",
    "    'order_reviews': order_reviews_cleaned,\n",
    "    'products': products_cleaned,\n",
    "    'sellers': sellers,\n",
    "    'geolocation': geo_agg,  # aggregated geolocation\n",
    "    'category_name_translation': category_name_translation\n",
    "}\n",
    "\n",
    "# Save only cleaned datasets\n",
    "for name, df in datasets.items():\n",
    "    if cleaned_status[name]:\n",
    "        df.to_csv(f'cleaned_data/{name}.csv', index=False)\n",
    "        print(f\"{name} saved ✅\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
